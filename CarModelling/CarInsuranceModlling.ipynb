{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Machine Learning 1\n",
        "Identify the single feature of the data that is the best predictor of whether a customer will put in a claim (the \"outcome\" column), excluding the \"id\" column.\n",
        " Store as a DataFrame called best_feature_df, containing columns named \"best_feature\" and \"best_accuracy\" with the name of the feature with the highest accuracy, and the respective accuracy score.\n",
        "\n",
        "For More Visit:https://drive.google.com/drive/folders/1jVOdc9SFaQP77UWIiuv2sBQJ5islYKCe"
      ],
      "metadata": {
        "id": "SqYyeva5t71w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.formula.api import logit\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n"
      ],
      "metadata": {
        "id": "0IZD4BGdup75"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Logistic regression is typically used for binary classification tasks where the outcome variable has two possible values. For example,\n",
        " predicting whether a customer will make a claim (yes or no), whether an email is spam or not, or whether a patient has a disease or not\n",
        "\n",
        " #**Insurance** Claims Prediction:\n",
        "\n",
        "Binary Outcome: Predicting whether a customer will make a claim (yes or no) based on features such as age, income, and driving experience.\n",
        "Application: Helps insurance companies to manage risk and optimize pricing.\n"
      ],
      "metadata": {
        "id": "fPC713_Wvmvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('/content/car_insurance.csv')\n",
        "\n",
        "\n",
        "# Display the first few rows and data types of the dataset\n",
        "print(data.head())\n",
        "print(data.dtypes)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYrTajd8vsQf",
        "outputId": "3c4bddc7-0b22-4875-d4c9-a4254aaa71c5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       id  age  gender driving_experience    education         income  \\\n",
            "0  569520    3       0               0-9y  high school    upper class   \n",
            "1  750365    0       1               0-9y         none        poverty   \n",
            "2  199901    0       0               0-9y  high school  working class   \n",
            "3  478866    0       1               0-9y   university  working class   \n",
            "4  731664    1       1             10-19y         none  working class   \n",
            "\n",
            "   credit_score  vehicle_ownership vehicle_year  married  children  \\\n",
            "0      0.629027                1.0   after 2015      0.0       1.0   \n",
            "1      0.357757                0.0  before 2015      0.0       0.0   \n",
            "2      0.493146                1.0  before 2015      0.0       0.0   \n",
            "3      0.206013                1.0  before 2015      0.0       1.0   \n",
            "4      0.388366                1.0  before 2015      0.0       0.0   \n",
            "\n",
            "   postal_code  annual_mileage vehicle_type  speeding_violations  duis  \\\n",
            "0        10238         12000.0        sedan                    0     0   \n",
            "1        10238         16000.0        sedan                    0     0   \n",
            "2        10238         11000.0        sedan                    0     0   \n",
            "3        32765         11000.0        sedan                    0     0   \n",
            "4        32765         12000.0        sedan                    2     0   \n",
            "\n",
            "   past_accidents  outcome  \n",
            "0               0      0.0  \n",
            "1               0      1.0  \n",
            "2               0      0.0  \n",
            "3               0      0.0  \n",
            "4               1      1.0  \n",
            "id                       int64\n",
            "age                      int64\n",
            "gender                   int64\n",
            "driving_experience      object\n",
            "education               object\n",
            "income                  object\n",
            "credit_score           float64\n",
            "vehicle_ownership      float64\n",
            "vehicle_year            object\n",
            "married                float64\n",
            "children               float64\n",
            "postal_code              int64\n",
            "annual_mileage         float64\n",
            "vehicle_type            object\n",
            "speeding_violations      int64\n",
            "duis                     int64\n",
            "past_accidents           int64\n",
            "outcome                float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Separate the target variable and features\n",
        "X = data.drop(columns=['outcome'])\n",
        "y = data['outcome']\n",
        "# y depend on x\n"
      ],
      "metadata": {
        "id": "t5WasvUmv9PR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle categorical features\n",
        "# Identify categorical columns and Use one-hot encoding to convert categorical features into numeric\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Dropping the first category in one-hot encoding ensures\n",
        "#  that you avoid multicollinearity by not including redundant information."
      ],
      "metadata": {
        "id": "9nmqHt27ABXz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply one-hot encoding to categorical features\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# Prepare to store the best feature and its accuracy\n",
        "best_accuracy = 0\n",
        "best_feature = None\n",
        "\n"
      ],
      "metadata": {
        "id": "IVSgrqkKAGFo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each feature and fit a logistic regression model\n",
        "for feature in X_encoded.columns:\n",
        "    # Prepare feature data\n",
        "    X_feature = X_encoded[[feature]]\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_feature, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Train a logistic regression model\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and calculate accuracy\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Check if this feature gives a better accuracy\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_feature = feature\n",
        "\n",
        "# Create a DataFrame to store the best performing feature and its accuracy\n",
        "best_feature_df = pd.DataFrame({\"best_feature\": [best_feature], \"best_accuracy\": [best_accuracy]})\n",
        "\n",
        "# Print the best performing feature and its accuracy\n",
        "print(best_feature_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKFFAbd0AKt8",
        "outputId": "f2c4c240-fe6a-43b0-f7e4-a70df72645b5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  best_feature  best_accuracy\n",
            "0          age       0.781186\n"
          ]
        }
      ]
    }
  ]
}